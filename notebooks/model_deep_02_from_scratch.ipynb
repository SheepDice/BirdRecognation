{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dropout, GlobalAveragePooling2D, Dense, LeakyReLU, Conv2D, MaxPooling2D,\\\n",
    "      Flatten, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import Model\n",
    "from timeit import default_timer as timer\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import const\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define dataset path and Timingcallback class\n",
    "\n",
    "dataset_used = const.DATASET_REDUIT\n",
    "\n",
    "diverted_images_train_path = os.path.join(dataset_used, \"train\")\n",
    "diverted_images_valid_path = os.path.join(dataset_used, \"valid\")\n",
    "diverted_images_test_path = os.path.join(dataset_used, \"test\")\n",
    "\n",
    "class TimingCallback(Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define callbacks objects\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor=\"val_loss\", patience=2, min_delta=0.01, factor=0.1, cooldown=4, verbose=1)\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.01, verbose=1, mode='min', monitor='val_loss')\n",
    "time_callback = TimingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define building moodel functions\n",
    "def build_model_dense(nb_class, dense_activation='relu', dropout_rate=0.2, dense_kernel_regularizer = None,\n",
    "                unit_first_dense=1024):\n",
    "    input_layer = Input(shape=(224, 224, 3))\n",
    "    x = GlobalAveragePooling2D()(input_layer)\n",
    "    x = Dense(unit_first_dense, activation=dense_activation)(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    x = Dense(unit_first_dense/2, activation=dense_activation)(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    predictions = Dense(nb_class, activation='softmax')(x)\n",
    "    model = Model(inputs=input_layer, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "def build_model_cnn(nb_class, conv2D_activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation=conv2D_activation, input_shape=(224, 224, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation=conv2D_activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation=conv2D_activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation=conv2D_activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation=conv2D_activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation=conv2D_activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_class, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First try with dense model\n",
    "batch_size = 16\n",
    "\n",
    "train_generator = ImageDataGenerator().flow_from_directory(diverted_images_train_path, target_size=(224, 224), batch_size=batch_size)\n",
    "valid_generator = ImageDataGenerator().flow_from_directory(diverted_images_valid_path, target_size=(224, 224), batch_size=batch_size)\n",
    "test_generator = ImageDataGenerator().flow_from_directory(diverted_images_test_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "nb_class = train_generator.num_classes\n",
    "\n",
    "model = build_model_dense(nb_class)\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc', 'mean_absolute_error'])\n",
    "\n",
    "history_diverted = model.fit(train_generator,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "                    callbacks=[reduce_learning_rate, early_stopping, time_callback], verbose=1)\n",
    "\n",
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)\n",
    "print(history_diverted.history['val_acc'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increase batch size and change Adam learning rate\n",
    "batch_size = 20\n",
    "\n",
    "train_generator = ImageDataGenerator().flow_from_directory(diverted_images_train_path, target_size=(224, 224), batch_size=batch_size)\n",
    "valid_generator = ImageDataGenerator().flow_from_directory(diverted_images_valid_path, target_size=(224, 224), batch_size=batch_size)\n",
    "test_generator = ImageDataGenerator().flow_from_directory(diverted_images_test_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "nb_class = train_generator.num_classes\n",
    "\n",
    "model = build_model_dense(nb_class)\n",
    "#model.summary()\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc', 'mean_absolute_error'])\n",
    "\n",
    "history_diverted = model.fit(train_generator,\n",
    "                    epochs=5,\n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "                    callbacks=[reduce_learning_rate, early_stopping, time_callback], verbose=1)\n",
    "\n",
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)\n",
    "print(history_diverted.history['val_acc'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change dropout rate\n",
    "batch_size = 20\n",
    "\n",
    "valid_generator = ImageDataGenerator().flow_from_directory(diverted_images_valid_path, target_size=(224, 224), batch_size=batch_size)\n",
    "test_generator = ImageDataGenerator().flow_from_directory(diverted_images_test_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    diverted_images_train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "nb_class = train_generator.num_classes\n",
    "\n",
    "model = build_model_dense(nb_class, dropout_rate=0.5)\n",
    "#model.summary()\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc', 'mean_absolute_error'])\n",
    "\n",
    "history_diverted = model.fit(train_generator,\n",
    "                    epochs=5,\n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "                    callbacks=[reduce_learning_rate, early_stopping, time_callback], verbose=1)\n",
    "\n",
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)\n",
    "print(history_diverted.history['val_acc'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change optimizer from Adam to SGD, add kernel regularizer and change unit value for denses layers\n",
    "batch_size = 20\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(diverted_images_train_path, target_size=(224, 224), batch_size=batch_size)\n",
    "valid_generator = ImageDataGenerator().flow_from_directory(diverted_images_valid_path, target_size=(224, 224), batch_size=batch_size)\n",
    "test_generator = ImageDataGenerator().flow_from_directory(diverted_images_test_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "nb_class = train_generator.num_classes\n",
    "\n",
    "model = build_model_dense(nb_class, dropout_rate=0.5, dense_kernel_regularizer=l2(0.01), unit_first_dense=2048)\n",
    "#model.summary()\n",
    "\n",
    "optimizer = SGD(learning_rate=0.01) \n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc', 'mean_absolute_error'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "history_diverted = model.fit(train_generator,\n",
    "                    epochs=5,\n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "                    callbacks=[reduce_learning_rate, early_stopping, time_callback], verbose=1)\n",
    "\n",
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)\n",
    "print(history_diverted.history['val_acc'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First try with a simple CNN model\n",
    "batch_size = 20\n",
    "\n",
    "valid_generator = ImageDataGenerator().flow_from_directory(diverted_images_valid_path, target_size=(224, 224), batch_size=batch_size)\n",
    "test_generator = ImageDataGenerator().flow_from_directory(diverted_images_test_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    diverted_images_train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "nb_class = train_generator.num_classes\n",
    "def build_model_cnn(nb_class, conv2d_activation='relu'):\n",
    "    input_layer = Input(shape=(224, 224, 3))\n",
    "    x = Conv2D(32, (3, 3), activation=conv2d_activation)(input_layer)  \n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "    x = Conv2D(64, (3, 3), activation=conv2d_activation)(x)  \n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)  \n",
    "    x = Flatten()(x) \n",
    "    x = Dense(128, activation='relu')(x)  \n",
    "    predictions = Dense(nb_class, activation='softmax')(x)  \n",
    "    model = Model(inputs=input_layer, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "model = build_model_cnn(nb_class)\n",
    "#model.summary()\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc', 'mean_absolute_error'])\n",
    "\n",
    "history_diverted = model.fit(train_generator,\n",
    "                    epochs=5,\n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "                    callbacks=[reduce_learning_rate, early_stopping, time_callback], verbose=1)\n",
    "\n",
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)\n",
    "print(history_diverted.history['val_acc'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complexification of CNN model\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "valid_generator = ImageDataGenerator().flow_from_directory(diverted_images_valid_path, target_size=(224, 224), batch_size=batch_size)\n",
    "test_generator = ImageDataGenerator().flow_from_directory(diverted_images_test_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    diverted_images_train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "nb_class = train_generator.num_classes\n",
    "\n",
    "model = build_model_cnn(nb_class)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc', 'mean_absolute_error'])\n",
    "\n",
    "history_diverted = model.fit(train_generator,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "                    callbacks=[reduce_learning_rate, early_stopping, time_callback], verbose=1)\n",
    "\n",
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)\n",
    "print(history_diverted.history['val_acc'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with data augmentation (best model)\n",
    "batch_size = 16\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(diverted_images_train_path, target_size=(224, 224), \n",
    "                                                    batch_size=batch_size, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory(diverted_images_valid_path, target_size=(224, 224), \n",
    "                                                    batch_size=batch_size, class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory(diverted_images_test_path, target_size=(224, 224), \n",
    "                                                  batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "nb_class = train_generator.num_classes\n",
    "\n",
    "model = build_model_cnn(nb_class)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc', 'mean_absolute_error'])\n",
    "\n",
    "history_diverted = model.fit(train_generator,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "                    callbacks=[reduce_learning_rate, early_stopping, time_callback], verbose=1)\n",
    "\n",
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)\n",
    "print(history_diverted.history['val_acc'][-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
