{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Code\\Datascience\\reco_oiseau_jan24bds\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB2, EfficientNetB0\n",
    "from tensorflow.keras.layers import Dropout, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import const\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des constantes\n",
    "\n",
    "class TimingCallback(Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)\n",
    "\n",
    "time_callback = TimingCallback()\n",
    "\n",
    "\n",
    "# Définition des chemins\n",
    "# dataset_path = const.DATASET_REDUIT\n",
    "dataset_path = const.DATASET_CLEAN_WO_BACKGROUND\n",
    "# dataset_path = const.DATASET_CLEAN_PATH\n",
    "# dataset_path = const.DATASET_CONTOUR\n",
    "# dataset_path = const.DATASET_WO_BACKGROUND\n",
    "\n",
    "diverted_images_train_path = os.path.join(dataset_path, \"train\")\n",
    "diverted_images_valid_path = os.path.join(dataset_path, \"valid\")\n",
    "diverted_images_test_path = os.path.join(dataset_path, \"test\")\n",
    "\n",
    "# Définition de la taille du lot\n",
    "batch_size = 16\n",
    "\n",
    "# Définition des callbacks\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor=\"val_loss\", patience=2, min_delta=0.01, factor=0.1, cooldown=4, verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.01, verbose=1, mode='min', monitor='val_loss')\n",
    "\n",
    "# Création du générateurs d'images de test\n",
    "test_generator = ImageDataGenerator().flow_from_directory(diverted_images_test_path, target_size=(224, 224), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction du modèle\n",
    "def build_model(num_classes, type_Efficient, kernel_regularizer=None, rate_Droput=0.3):\n",
    "    if type_Efficient == \"B0\":\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False)\n",
    "    elif type_Efficient == \"B2\":\n",
    "        base_model = EfficientNetB2(weights='imagenet', include_top=False)\n",
    "    else:\n",
    "        raise ValueError(\"type_Efficient devrait être B0 ou B2\")\n",
    "    for layer in base_model.layers[:-20]:  \n",
    "        layer.trainable = False\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1280, activation='relu', kernel_regularizer=kernel_regularizer)(x) \n",
    "    x = Dropout(rate=rate_Droput)(x)\n",
    "    x = Dense(640, activation='relu', kernel_regularizer=kernel_regularizer)(x)  \n",
    "    x = Dropout(rate=rate_Droput)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modèle EfficientNet amélioré - meilleur modèle obtenu - val_acc 0.9561 - dataset images détourées\n",
    "# Création des générateurs d'images avec augmentation des données\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(diverted_images_train_path, target_size=(224, 224), batch_size=batch_size)\n",
    "valid_generator = ImageDataGenerator().flow_from_directory(diverted_images_valid_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "# Récupération du nombre de classes\n",
    "num_classes = train_generator.num_classes\n",
    "model = build_model(num_classes, type_Efficient=\"B2\", rate_Droput=0.2)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc', 'mean_absolute_error'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "history_diverted = model.fit(train_generator,\n",
    "                    epochs=15,  \n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "                    callbacks=[reduce_learning_rate, early_stopping, time_callback], verbose=1)\n",
    "\n",
    "# Évaluation du modèle\n",
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)\n",
    "print(history_diverted.history['val_acc'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modèle EfficientNet val_acc 0.91 - dataset images détourées\n",
    "\n",
    "# Création des générateurs d'images\n",
    "train_generator = ImageDataGenerator().flow_from_directory(diverted_images_train_path, target_size=(224, 224), batch_size=batch_size)\n",
    "valid_generator = ImageDataGenerator().flow_from_directory(diverted_images_valid_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "# Récupération du nombre de classes\n",
    "num_classes = train_generator.num_classes\n",
    "\n",
    "model = build_model(num_classes, type_Efficient=\"B0\", rate_Droput=0.2)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc', 'mean_absolute_error'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "history_diverted = model.fit(train_generator,\n",
    "                    epochs=15,\n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "                    callbacks=[reduce_learning_rate, early_stopping, time_callback], verbose=1)\n",
    "\n",
    "# Évaluation du modèle\n",
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)\n",
    "print(history_diverted.history['val_acc'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des générateurs d'images avec augmentation des données\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(diverted_images_train_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "valid_generator = valid_datagen.flow_from_directory(diverted_images_valid_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "model = build_model(num_classes, type_Efficient=\"B2\", kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['acc', 'mean_absolute_error'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "history_diverted = model.fit(train_generator,\n",
    "                    epochs=10,  \n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "                    callbacks=[reduce_learning_rate, early_stopping, time_callback], verbose=1)\n",
    "\n",
    "# Évaluation du modèle\n",
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)\n",
    "print(history_diverted.history['val_acc'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des générateurs d'images avec augmentation des données\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(diverted_images_train_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "valid_generator = valid_datagen.flow_from_directory(diverted_images_valid_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "model = build_model(num_classes, type_Efficient=\"B0\", kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['acc', 'mean_absolute_error'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "history_diverted = model.fit(train_generator,\n",
    "                    epochs=10,  \n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "                    callbacks=[reduce_learning_rate, early_stopping, time_callback], verbose=1)\n",
    "\n",
    "# Évaluation du modèle\n",
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)\n",
    "print(history_diverted.history['val_acc'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des générateurs d'images avec augmentation des données\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(diverted_images_train_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "valid_generator = valid_datagen.flow_from_directory(diverted_images_valid_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "model = build_model(num_classes, type_Efficient=\"B0\")\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['acc', 'mean_absolute_error'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "history_diverted = model.fit(train_generator,\n",
    "                    epochs=20,  \n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "                    callbacks=[reduce_learning_rate, early_stopping, time_callback], verbose=1)\n",
    "\n",
    "# Évaluation du modèle\n",
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)\n",
    "print(history_diverted.history['val_acc'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des générateurs d'images avec augmentation des données\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(diverted_images_train_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "valid_generator = valid_datagen.flow_from_directory(diverted_images_valid_path, target_size=(224, 224), batch_size=batch_size)\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "model = build_model(num_classes, type_Efficient=\"B0\")\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['acc', 'mean_absolute_error'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "history_diverted = model.fit(train_generator,\n",
    "                    epochs=20,  \n",
    "                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "                    callbacks=[reduce_learning_rate, early_stopping, time_callback], verbose=1)\n",
    "\n",
    "# Évaluation du modèle\n",
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)\n",
    "print(history_diverted.history['val_acc'][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
